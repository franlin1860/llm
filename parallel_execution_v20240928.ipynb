{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/franlin1860/llm/blob/main/parallel_execution_v20240928.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pv3jA9B5SuSL"
      },
      "source": [
        "# Parallel Execution of Same Event Example\n",
        "\n",
        "In this example, we'll demonstrate how to use the workflow functionality to achieve similar capabilities while allowing parallel execution of multiple events of the same type.  \n",
        "By setting the `num_workers` parameter in `@step` decorator, we can control the number of steps executed simultaneously, enabling efficient parallel processing.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prevent Disconnection"
      ],
      "metadata": {
        "id": "iYT8KZrXTaAK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown <h3>← 输入了代码后运行以防止断开</h>\n",
        "import IPython\n",
        "from google.colab import output\n",
        "\n",
        "display(IPython.display.Javascript('''\n",
        " function ClickConnect(){\n",
        "   btn = document.querySelector(\"colab-connect-button\")\n",
        "   if (btn != null){\n",
        "     console.log(\"Click colab-connect-button\");\n",
        "     btn.click()\n",
        "     }\n",
        "\n",
        "   btn = document.getElementById('ok')\n",
        "   if (btn != null){\n",
        "     console.log(\"Click reconnect\");\n",
        "     btn.click()\n",
        "     }\n",
        "  }\n",
        "\n",
        "setInterval(ClickConnect,60000)\n",
        "'''))\n",
        "\n",
        "print(\"Done.\")"
      ],
      "metadata": {
        "id": "wAK0ogGiTfR9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "89928375-7f8c-42c7-ef12-e889ffd9446b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              " function ClickConnect(){\n",
              "   btn = document.querySelector(\"colab-connect-button\")\n",
              "   if (btn != null){\n",
              "     console.log(\"Click colab-connect-button\");\n",
              "     btn.click()\n",
              "     }\n",
              "\n",
              "   btn = document.getElementById('ok')\n",
              "   if (btn != null){\n",
              "     console.log(\"Click reconnect\");\n",
              "     btn.click()\n",
              "     }\n",
              "  }\n",
              "\n",
              "setInterval(ClickConnect,60000)\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "function ConnectButton(){\n",
        "    console.log(\"Connect pushed\");\n",
        "    document.querySelector(\"#connect\").click()\n",
        "}\n",
        "setInterval(ConnectButton,60000);"
      ],
      "metadata": {
        "id": "luLx-0aKT0Bq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Pdqb1haSuSR"
      },
      "source": [
        "\n",
        "# Installing Dependencies\n",
        "\n",
        "First, we need to install the necessary dependencies:\n",
        "\n",
        "* LlamaIndex core for most functionalities\n",
        "* llama-index-utils-workflow for workflow capabilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hjbmOOVkSuSS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "f82aa5bb-3dec-46d2-8eff-ef080da8c6f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-index-core\n",
            "  Downloading llama_index_core-0.11.14-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting llama-index-utils-workflow\n",
            "  Downloading llama_index_utils_workflow-0.2.1-py3-none-any.whl.metadata (667 bytes)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core) (2.0.35)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (3.10.5)\n",
            "Collecting dataclasses-json (from llama-index-core)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting deprecated>=1.2.9.3 (from llama-index-core)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core)\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (2024.6.1)\n",
            "Collecting httpx (from llama-index-core)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (3.3)\n",
            "Collecting nltk>3.8.1 (from llama-index-core)\n",
            "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (1.26.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (10.4.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (2.9.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (2.32.3)\n",
            "Collecting tenacity!=8.4.0,<9.0.0,>=8.2.0 (from llama-index-core)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting tiktoken>=0.3.3 (from llama-index-core)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (4.12.2)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index-core)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (1.16.0)\n",
            "Collecting pyvis<0.4.0,>=0.3.2 (from llama-index-utils-workflow)\n",
            "  Downloading pyvis-0.3.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (4.0.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core) (2024.9.11)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core) (2.23.4)\n",
            "Requirement already satisfied: ipython>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (7.34.0)\n",
            "Requirement already satisfied: jinja2>=2.9.6 in /usr/local/lib/python3.10/dist-packages (from pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (3.1.4)\n",
            "Requirement already satisfied: jsonpickle>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (3.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core) (3.1.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core)\n",
            "  Downloading marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core) (3.7.1)\n",
            "Collecting httpcore==1.* (from httpx->llama-index-core)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->llama-index-core)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (71.0.4)\n",
            "Collecting jedi>=0.16 (from ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow)\n",
            "  Using cached jedi-0.19.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (3.0.47)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (4.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.9.6->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (2.1.5)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core) (24.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core) (1.2.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (0.2.13)\n",
            "Downloading llama_index_core-0.11.14-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_utils_workflow-0.2.1-py3-none-any.whl (2.6 kB)\n",
            "Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyvis-0.3.2-py3-none-any.whl (756 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.22.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "Installing collected packages: dirtyjson, tenacity, nltk, mypy-extensions, marshmallow, jedi, h11, deprecated, typing-inspect, tiktoken, httpcore, pyvis, httpx, dataclasses-json, llama-index-core, llama-index-utils-workflow\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.8.1\n",
            "    Uninstalling nltk-3.8.1:\n",
            "      Successfully uninstalled nltk-3.8.1\n",
            "Successfully installed dataclasses-json-0.6.7 deprecated-1.2.14 dirtyjson-1.0.8 h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 jedi-0.19.1 llama-index-core-0.11.14 llama-index-utils-workflow-0.2.1 marshmallow-3.22.0 mypy-extensions-1.0.0 nltk-3.9.1 pyvis-0.3.2 tenacity-8.5.0 tiktoken-0.7.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install llama-index-core llama-index-utils-workflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edMGIge4SuSU"
      },
      "source": [
        "# Importing Required Libraries\n",
        "After installing the dependencies, we can import the required libraries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Gf1kFKRHSuSU"
      },
      "outputs": [],
      "source": [
        "import asyncio\n",
        "from llama_index.core.workflow import (\n",
        "    step,\n",
        "    Context,\n",
        "    Workflow,\n",
        "    Event,\n",
        "    StartEvent,\n",
        "    StopEvent,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJjUKxZRSuSV"
      },
      "source": [
        "We will create two workflows: one that can process multiple data items in parallel by using the `@step(num_workers=N)` decorator, and another without setting num_workers, for comparison.  \n",
        "By using the `num_workers` parameter in the `@step` decorator, we can limit the number of steps executed simultaneously, thus controlling the level of parallelism. This approach is particularly suitable for scenarios that require processing similar tasks while managing resource usage.  \n",
        "For example, you can execute multiple sub-queries at once, but please note that num_workers cannot be set without limits. It depends on  your workload or token limits.\n",
        "# Defining Event Types\n",
        "We'll define two event types: one for input events to be processed, and another for processing results:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "lTNJwKJFSuSV"
      },
      "outputs": [],
      "source": [
        "class ProcessEvent(Event):\n",
        "    data: str\n",
        "\n",
        "\n",
        "class ResultEvent(Event):\n",
        "    result: str"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDRiDagZSuSW"
      },
      "source": [
        "# Creating Sequential and Parallel Workflows\n",
        "Now, we'll create a SequentialWorkflow and a ParallelWorkflow class that includes three main steps:\n",
        "\n",
        "- start: Initialize and send multiple parallel events\n",
        "- process_data: Process data\n",
        "- combine_results: Collect and merge all processing results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "iptwDQaPSuSW"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "\n",
        "class SequentialWorkflow(Workflow):\n",
        "    @step\n",
        "    async def start(self, ctx: Context, ev: StartEvent) -> ProcessEvent:\n",
        "        data_list = [\"A\", \"B\", \"C\"]\n",
        "        await ctx.set(\"num_to_collect\", len(data_list))\n",
        "        for item in data_list:\n",
        "            self.send_event(ProcessEvent(data=item))\n",
        "        return None\n",
        "\n",
        "    @step\n",
        "    async def process_data(self, ev: ProcessEvent) -> ResultEvent:\n",
        "        # Simulate some time-consuming processing\n",
        "        await asyncio.sleep(random.randint(1, 2))\n",
        "        result = f\"Processed: {ev.data}\"\n",
        "        print(f\"Completed processing: {ev.data}\")\n",
        "        return ResultEvent(result=result)\n",
        "\n",
        "    @step\n",
        "    async def combine_results(\n",
        "        self, ctx: Context, ev: ResultEvent\n",
        "    ) -> StopEvent | None:\n",
        "        num_to_collect = await ctx.get(\"num_to_collect\")\n",
        "        results = ctx.collect_events(ev, [ResultEvent] * num_to_collect)\n",
        "        if results is None:\n",
        "            return None\n",
        "\n",
        "        combined_result = \", \".join([event.result for event in results])\n",
        "        return StopEvent(result=combined_result)\n",
        "\n",
        "\n",
        "class ParallelWorkflow(Workflow):\n",
        "    @step\n",
        "    async def start(self, ctx: Context, ev: StartEvent) -> ProcessEvent:\n",
        "        data_list = [\"A\", \"B\", \"C\"]\n",
        "        await ctx.set(\"num_to_collect\", len(data_list))\n",
        "        for item in data_list:\n",
        "            self.send_event(ProcessEvent(data=item))\n",
        "        return None\n",
        "\n",
        "    @step(num_workers=3)\n",
        "    async def process_data(self, ev: ProcessEvent) -> ResultEvent:\n",
        "        # Simulate some time-consuming processing\n",
        "        await asyncio.sleep(random.randint(1, 2))\n",
        "        result = f\"Processed: {ev.data}\"\n",
        "        print(f\"Completed processing: {ev.data}\")\n",
        "        return ResultEvent(result=result)\n",
        "\n",
        "    @step\n",
        "    async def combine_results(\n",
        "        self, ctx: Context, ev: ResultEvent\n",
        "    ) -> StopEvent | None:\n",
        "        num_to_collect = await ctx.get(\"num_to_collect\")\n",
        "        results = ctx.collect_events(ev, [ResultEvent] * num_to_collect)\n",
        "        if results is None:\n",
        "            return None\n",
        "\n",
        "        combined_result = \", \".join([event.result for event in results])\n",
        "        return StopEvent(result=combined_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjUUTsq1SuSX"
      },
      "source": [
        "In these two workflows:\n",
        "\n",
        "- The start method initializes and sends multiple ProcessEvent.\n",
        "- The process_data method uses\n",
        "  - only the `@step` decorator in SequentialWorkflow\n",
        "  - uses the `@step(num_workers=3)` decorator in ParallelWorkflow to limit the number of simultaneously executing workers to 3.\n",
        "- The combine_results method collects all processing results and merges them.\n",
        "\n",
        "# Running the Workflow\n",
        "Finally, we can create a main function to run our workflow:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "lcTTqhA1SuSX",
        "outputId": "23738986-ddcd-4834-a68d-991b92f7f1b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start a sequential workflow without setting num_workers in the step of process_data\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/llama_index/core/workflow/workflow.py:285: UserWarning: Use a Context instance to send events from a step. Make sure your step method or function takes a parameter of type Context like `ctx: Context` and replace `self.send_event(...)` with `ctx.send_event(...)` in your code.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed processing: A\n",
            "Completed processing: B\n",
            "Completed processing: C\n",
            "Workflow result: Processed: A, Processed: B, Processed: C\n",
            "Time taken: 1.0185067653656006 seconds\n",
            "------------------------------\n",
            "Start a parallel workflow with setting num_workers in the step of process_data\n",
            "Completed processing: A\n",
            "Completed processing: C\n",
            "Completed processing: B\n",
            "Workflow result: Processed: A, Processed: C, Processed: B\n",
            "Time taken: 2.0080888271331787 seconds\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "sequential_workflow = SequentialWorkflow()\n",
        "\n",
        "print(\n",
        "    \"Start a sequential workflow without setting num_workers in the step of process_data\"\n",
        ")\n",
        "start_time = time.time()\n",
        "result = await sequential_workflow.run()\n",
        "end_time = time.time()\n",
        "print(f\"Workflow result: {result}\")\n",
        "print(f\"Time taken: {end_time - start_time} seconds\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "parallel_workflow = ParallelWorkflow()\n",
        "\n",
        "print(\n",
        "    \"Start a parallel workflow with setting num_workers in the step of process_data\"\n",
        ")\n",
        "start_time = time.time()\n",
        "result = await parallel_workflow.run()\n",
        "end_time = time.time()\n",
        "print(f\"Workflow result: {result}\")\n",
        "print(f\"Time taken: {end_time - start_time} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gd-6s9-SuSZ"
      },
      "source": [
        "# Note\n",
        "\n",
        "- Without setting num_workers, it might take 3 to 6 seconds. By setting num_workers, the processing occurs in parallel, handling 3 items at a time, and only takes 2 seconds.\n",
        "- In ParallelWorkflow, the order of the completed results may differ from the input order, depending on the completion time of the tasks.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M038QC3mSuSZ"
      },
      "source": [
        "This example demonstrates the execution speed with and without using num_workers, and how to implement parallel processing in a workflow. By setting num_workers, we can control the degree of parallelism, which is very useful for scenarios that need to balance performance and resource usage."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}