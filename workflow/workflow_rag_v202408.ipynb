{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjRA0fKzvTsw"
      },
      "source": [
        "# RAG Workflow with Reranking\n",
        "\n",
        "This notebook walks through setting up a `Workflow` to perform basic RAG with reranking."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#   防断开"
      ],
      "metadata": {
        "id": "N0bQTB8uvuZ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown <h3>← 输入了代码后运行以防止断开</h>\n",
        "\n",
        "\n",
        "import IPython\n",
        "from google.colab import output\n",
        "\n",
        "display(IPython.display.Javascript('''\n",
        " function ClickConnect(){\n",
        "   btn = document.querySelector(\"colab-connect-button\")\n",
        "   if (btn != null){\n",
        "     console.log(\"Click colab-connect-button\");\n",
        "     btn.click()\n",
        "     }\n",
        "\n",
        "   btn = document.getElementById('ok')\n",
        "   if (btn != null){\n",
        "     console.log(\"Click reconnect\");\n",
        "     btn.click()\n",
        "     }\n",
        "  }\n",
        "\n",
        "setInterval(ClickConnect,60000)\n",
        "'''))\n",
        "\n",
        "print(\"Done.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "Y8JxgQxov1AL",
        "outputId": "120732de-7e5e-4009-acbe-8157009f04a0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              " function ClickConnect(){\n",
              "   btn = document.querySelector(\"colab-connect-button\")\n",
              "   if (btn != null){\n",
              "     console.log(\"Click colab-connect-button\");\n",
              "     btn.click()\n",
              "     }\n",
              "\n",
              "   btn = document.getElementById('ok')\n",
              "   if (btn != null){\n",
              "     console.log(\"Click reconnect\");\n",
              "     btn.click()\n",
              "     }\n",
              "  }\n",
              "\n",
              "setInterval(ClickConnect,60000)\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "function ConnectButton(){\n",
        "    console.log(\"Connect pushed\");\n",
        "    document.querySelector(\"#connect\").click()\n",
        "}\n",
        "setInterval(ConnectButton,60000);\n"
      ],
      "metadata": {
        "id": "OudzjtWrwAJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# APP begin"
      ],
      "metadata": {
        "id": "fl0h1ar-wa7_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_r4iH9YjvTs3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "27831fc0-191a-411d-9e3a-81c19019ad1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-index\n",
            "  Downloading llama_index-0.10.65-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting llama-index-agent-openai<0.3.0,>=0.1.4 (from llama-index)\n",
            "  Downloading llama_index_agent_openai-0.2.9-py3-none-any.whl.metadata (729 bytes)\n",
            "Collecting llama-index-cli<0.2.0,>=0.1.2 (from llama-index)\n",
            "  Downloading llama_index_cli-0.1.13-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting llama-index-core<0.11.0,>=0.10.65 (from llama-index)\n",
            "  Downloading llama_index_core-0.10.65-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting llama-index-embeddings-openai<0.2.0,>=0.1.5 (from llama-index)\n",
            "  Downloading llama_index_embeddings_openai-0.1.11-py3-none-any.whl.metadata (655 bytes)\n",
            "Collecting llama-index-indices-managed-llama-cloud>=0.2.0 (from llama-index)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.2.7-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama-index)\n",
            "  Downloading llama_index_legacy-0.9.48.post1-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting llama-index-llms-openai<0.2.0,>=0.1.27 (from llama-index)\n",
            "  Downloading llama_index_llms_openai-0.1.29-py3-none-any.whl.metadata (650 bytes)\n",
            "Collecting llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 (from llama-index)\n",
            "  Downloading llama_index_multi_modal_llms_openai-0.1.9-py3-none-any.whl.metadata (728 bytes)\n",
            "Collecting llama-index-program-openai<0.2.0,>=0.1.3 (from llama-index)\n",
            "  Downloading llama_index_program_openai-0.1.7-py3-none-any.whl.metadata (760 bytes)\n",
            "Collecting llama-index-question-gen-openai<0.2.0,>=0.1.2 (from llama-index)\n",
            "  Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl.metadata (785 bytes)\n",
            "Collecting llama-index-readers-file<0.2.0,>=0.1.4 (from llama-index)\n",
            "  Downloading llama_index_readers_file-0.1.33-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting llama-index-readers-llama-parse>=0.1.2 (from llama-index)\n",
            "  Downloading llama_index_readers_llama_parse-0.1.6-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting openai>=1.14.0 (from llama-index-agent-openai<0.3.0,>=0.1.4->llama-index)\n",
            "  Downloading openai-1.40.6-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.65->llama-index) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.65->llama-index) (2.0.32)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.65->llama-index) (3.10.2)\n",
            "Collecting dataclasses-json (from llama-index-core<0.11.0,>=0.10.65->llama-index)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.11.0,>=0.10.65->llama-index)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.11.0,>=0.10.65->llama-index)\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.65->llama-index) (2024.6.1)\n",
            "Collecting httpx (from llama-index-core<0.11.0,>=0.10.65->llama-index)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.65->llama-index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.65->llama-index) (3.3)\n",
            "Collecting nltk>=3.8.2 (from llama-index-core<0.11.0,>=0.10.65->llama-index)\n",
            "  Downloading nltk-3.8.2-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.65->llama-index) (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.65->llama-index) (2.1.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.65->llama-index) (9.4.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.65->llama-index) (2.32.3)\n",
            "Collecting tenacity!=8.4.0,<9.0.0,>=8.2.0 (from llama-index-core<0.11.0,>=0.10.65->llama-index)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting tiktoken>=0.3.3 (from llama-index-core<0.11.0,>=0.10.65->llama-index)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.65->llama-index) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.65->llama-index) (4.12.2)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.11.0,>=0.10.65->llama-index)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.65->llama-index) (1.16.0)\n",
            "Collecting llama-cloud>=0.0.11 (from llama-index-indices-managed-llama-cloud>=0.2.0->llama-index)\n",
            "  Downloading llama_cloud-0.0.13-py3-none-any.whl.metadata (751 bytes)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.12.3)\n",
            "Collecting pypdf<5.0.0,>=4.0.1 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
            "  Downloading pypdf-4.3.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
            "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.1.2->llama-index)\n",
            "  Downloading llama_parse-0.4.9-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.65->llama-index) (2.3.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.65->llama-index) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.65->llama-index) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.65->llama-index) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.65->llama-index) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.65->llama-index) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.65->llama-index) (4.0.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (2.5)\n",
            "Requirement already satisfied: pydantic>=1.10 in /usr/local/lib/python3.10/dist-packages (from llama-cloud>=0.0.11->llama-index-indices-managed-llama-cloud>=0.2.0->llama-index) (2.8.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.65->llama-index) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.65->llama-index) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx->llama-index-core<0.11.0,>=0.10.65->llama-index)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.65->llama-index) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.65->llama-index) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.65->llama-index)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.8.2->llama-index-core<0.11.0,>=0.10.65->llama-index) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.8.2->llama-index-core<0.11.0,>=0.10.65->llama-index) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.8.2->llama-index-core<0.11.0,>=0.10.65->llama-index) (2024.5.15)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.3.0,>=0.1.4->llama-index) (1.7.0)\n",
            "Collecting jiter<1,>=0.4.0 (from openai>=1.14.0->llama-index-agent-openai<0.3.0,>=0.1.4->llama-index)\n",
            "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.65->llama-index) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.65->llama-index) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.65->llama-index) (3.0.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.65->llama-index)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.11.0,>=0.10.65->llama-index)\n",
            "  Downloading marshmallow-3.21.3-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.65->llama-index) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.65->llama-index) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.65->llama-index) (2024.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.65->llama-index) (1.2.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.65->llama-index) (24.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llama-cloud>=0.0.11->llama-index-indices-managed-llama-cloud>=0.2.0->llama-index) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llama-cloud>=0.0.11->llama-index-indices-managed-llama-cloud>=0.2.0->llama-index) (2.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.65->llama-index) (1.16.0)\n",
            "Downloading llama_index-0.10.65-py3-none-any.whl (6.8 kB)\n",
            "Downloading llama_index_agent_openai-0.2.9-py3-none-any.whl (13 kB)\n",
            "Downloading llama_index_cli-0.1.13-py3-none-any.whl (27 kB)\n",
            "Downloading llama_index_core-0.10.65-py3-none-any.whl (15.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.5/15.5 MB\u001b[0m \u001b[31m77.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_embeddings_openai-0.1.11-py3-none-any.whl (6.3 kB)\n",
            "Downloading llama_index_indices_managed_llama_cloud-0.2.7-py3-none-any.whl (9.5 kB)\n",
            "Downloading llama_index_legacy-0.9.48.post1-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_llms_openai-0.1.29-py3-none-any.whl (11 kB)\n",
            "Downloading llama_index_multi_modal_llms_openai-0.1.9-py3-none-any.whl (5.9 kB)\n",
            "Downloading llama_index_program_openai-0.1.7-py3-none-any.whl (5.3 kB)\n",
            "Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl (2.9 kB)\n",
            "Downloading llama_index_readers_file-0.1.33-py3-none-any.whl (38 kB)\n",
            "Downloading llama_index_readers_llama_parse-0.1.6-py3-none-any.whl (2.5 kB)\n",
            "Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Downloading llama_cloud-0.0.13-py3-none-any.whl (169 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.4/169.4 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_parse-0.4.9-py3-none-any.whl (9.4 kB)\n",
            "Downloading nltk-3.8.2-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.40.6-py3-none-any.whl (361 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m361.3/361.3 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf-4.3.1-py3-none-any.whl (295 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
            "Downloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: striprtf, dirtyjson, tenacity, pypdf, nltk, mypy-extensions, marshmallow, jiter, h11, deprecated, typing-inspect, tiktoken, httpcore, httpx, dataclasses-json, openai, llama-cloud, llama-index-legacy, llama-index-core, llama-parse, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.8.1\n",
            "    Uninstalling nltk-3.8.1:\n",
            "      Successfully uninstalled nltk-3.8.1\n",
            "Successfully installed dataclasses-json-0.6.7 deprecated-1.2.14 dirtyjson-1.0.8 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 jiter-0.5.0 llama-cloud-0.0.13 llama-index-0.10.65 llama-index-agent-openai-0.2.9 llama-index-cli-0.1.13 llama-index-core-0.10.65 llama-index-embeddings-openai-0.1.11 llama-index-indices-managed-llama-cloud-0.2.7 llama-index-legacy-0.9.48.post1 llama-index-llms-openai-0.1.29 llama-index-multi-modal-llms-openai-0.1.9 llama-index-program-openai-0.1.7 llama-index-question-gen-openai-0.1.3 llama-index-readers-file-0.1.33 llama-index-readers-llama-parse-0.1.6 llama-parse-0.4.9 marshmallow-3.21.3 mypy-extensions-1.0.0 nltk-3.8.2 openai-1.40.6 pypdf-4.3.1 striprtf-0.0.26 tenacity-8.5.0 tiktoken-0.7.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -U llama-index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "f-QKuzx2vTs5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"DEEPSEEK_API_KEY\"] = \"sk-\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ondfeBP6vTs6"
      },
      "source": [
        "### Get Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "AJos6j0KvTs8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "0591a5cb-39fd-433b-e8da-6b0bd129b431"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-08-15 02:13:44--  https://arxiv.org/pdf/2307.09288.pdf\n",
            "Resolving arxiv.org (arxiv.org)... 151.101.195.42, 151.101.67.42, 151.101.3.42, ...\n",
            "Connecting to arxiv.org (arxiv.org)|151.101.195.42|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://arxiv.org/pdf/2307.09288 [following]\n",
            "--2024-08-15 02:13:45--  http://arxiv.org/pdf/2307.09288\n",
            "Connecting to arxiv.org (arxiv.org)|151.101.195.42|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13661300 (13M) [application/pdf]\n",
            "Saving to: ‘data/llama2.pdf’\n",
            "\n",
            "data/llama2.pdf     100%[===================>]  13.03M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2024-08-15 02:13:45 (96.4 MB/s) - ‘data/llama2.pdf’ saved [13661300/13661300]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p data\n",
        "!wget --user-agent \"Mozilla\" \"https://arxiv.org/pdf/2307.09288.pdf\" -O \"data/llama2.pdf\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaGiEVg2vTs9"
      },
      "source": [
        "Since workflows are async first, this all runs fine in a notebook. If you were running in your own code, you would want to use `asyncio.run()` to start an async event loop if one isn't already running.\n",
        "\n",
        "```python\n",
        "async def main():\n",
        "    <async code>\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import asyncio\n",
        "    asyncio.run(main())\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LLM Env\n"
      ],
      "metadata": {
        "id": "Q12Oa0Vf0_pr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama_index-llms-openai_like\n",
        "!pip install llama_index-embeddings-huggingface"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Y8-9s9kK1HML",
        "outputId": "3a88cf74-3e41-43a0-c871-da1fc5121818"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama_index-llms-openai_like\n",
            "  Downloading llama_index_llms_openai_like-0.1.3-py3-none-any.whl.metadata (753 bytes)\n",
            "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from llama_index-llms-openai_like) (0.10.65)\n",
            "Requirement already satisfied: llama-index-llms-openai<0.2.0,>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from llama_index-llms-openai_like) (0.1.29)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.37.0 in /usr/local/lib/python3.10/dist-packages (from llama_index-llms-openai_like) (4.42.4)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index-llms-openai_like) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama_index-llms-openai_like) (2.0.32)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index-llms-openai_like) (3.10.2)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index-llms-openai_like) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index-llms-openai_like) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index-llms-openai_like) (1.0.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index-llms-openai_like) (2024.6.1)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index-llms-openai_like) (0.27.0)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index-llms-openai_like) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index-llms-openai_like) (3.3)\n",
            "Requirement already satisfied: nltk>=3.8.2 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index-llms-openai_like) (3.8.2)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index-llms-openai_like) (1.26.4)\n",
            "Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index-llms-openai_like) (1.40.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index-llms-openai_like) (2.1.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index-llms-openai_like) (9.4.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index-llms-openai_like) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index-llms-openai_like) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index-llms-openai_like) (0.7.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index-llms-openai_like) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index-llms-openai_like) (4.12.2)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index-llms-openai_like) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index-llms-openai_like) (1.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.37.0->llama_index-llms-openai_like) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.37.0->llama_index-llms-openai_like) (0.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.37.0->llama_index-llms-openai_like) (24.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.37.0->llama_index-llms-openai_like) (2024.5.15)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.37.0->llama_index-llms-openai_like) (0.4.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.37.0->llama_index-llms-openai_like) (0.19.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama_index-llms-openai_like) (2.3.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama_index-llms-openai_like) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama_index-llms-openai_like) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama_index-llms-openai_like) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama_index-llms-openai_like) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama_index-llms-openai_like) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama_index-llms-openai_like) (4.0.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.8.2->llama-index-core<0.11.0,>=0.10.1->llama_index-llms-openai_like) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.8.2->llama-index-core<0.11.0,>=0.10.1->llama_index-llms-openai_like) (1.4.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama_index-llms-openai_like) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama_index-llms-openai_like) (1.7.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama_index-llms-openai_like) (0.5.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama_index-llms-openai_like) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama_index-llms-openai_like) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama_index-llms-openai_like) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama_index-llms-openai_like) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama_index-llms-openai_like) (3.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama_index-llms-openai_like) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama_index-llms-openai_like) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama_index-llms-openai_like) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama_index-llms-openai_like) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama_index-llms-openai_like) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama_index-llms-openai_like) (3.21.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama_index-llms-openai_like) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama_index-llms-openai_like) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama_index-llms-openai_like) (2024.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama_index-llms-openai_like) (1.2.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama_index-llms-openai_like) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama_index-llms-openai_like) (2.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.1->llama_index-llms-openai_like) (1.16.0)\n",
            "Downloading llama_index_llms_openai_like-0.1.3-py3-none-any.whl (3.0 kB)\n",
            "Installing collected packages: llama_index-llms-openai_like\n",
            "Successfully installed llama_index-llms-openai_like-0.1.3\n",
            "Collecting llama_index-embeddings-huggingface\n",
            "  Downloading llama_index_embeddings_huggingface-0.2.3-py3-none-any.whl.metadata (769 bytes)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub[inference]>=0.19.0->llama_index-embeddings-huggingface) (0.23.5)\n",
            "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from llama_index-embeddings-huggingface) (0.10.65)\n",
            "Collecting sentence-transformers>=2.6.1 (from llama_index-embeddings-huggingface)\n",
            "  Downloading sentence_transformers-3.0.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama_index-embeddings-huggingface) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama_index-embeddings-huggingface) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama_index-embeddings-huggingface) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama_index-embeddings-huggingface) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama_index-embeddings-huggingface) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama_index-embeddings-huggingface) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama_index-embeddings-huggingface) (4.12.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from huggingface-hub[inference]>=0.19.0->llama_index-embeddings-huggingface) (3.10.2)\n",
            "Collecting minijinja>=1.0 (from huggingface-hub[inference]>=0.19.0->llama_index-embeddings-huggingface)\n",
            "  Downloading minijinja-2.0.1-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama_index-embeddings-huggingface) (2.0.32)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index-embeddings-huggingface) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index-embeddings-huggingface) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index-embeddings-huggingface) (1.0.8)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index-embeddings-huggingface) (0.27.0)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index-embeddings-huggingface) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index-embeddings-huggingface) (3.3)\n",
            "Requirement already satisfied: nltk>=3.8.2 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index-embeddings-huggingface) (3.8.2)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index-embeddings-huggingface) (1.26.4)\n",
            "Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index-embeddings-huggingface) (1.40.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index-embeddings-huggingface) (2.1.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index-embeddings-huggingface) (9.4.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index-embeddings-huggingface) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index-embeddings-huggingface) (0.7.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index-embeddings-huggingface) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index-embeddings-huggingface) (1.16.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.1->llama_index-embeddings-huggingface) (4.42.4)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.1->llama_index-embeddings-huggingface) (2.3.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.1->llama_index-embeddings-huggingface) (1.3.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.1->llama_index-embeddings-huggingface) (1.13.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama_index-embeddings-huggingface) (2.3.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama_index-embeddings-huggingface) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama_index-embeddings-huggingface) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama_index-embeddings-huggingface) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama_index-embeddings-huggingface) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama_index-embeddings-huggingface) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama_index-embeddings-huggingface) (4.0.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.8.2->llama-index-core<0.11.0,>=0.10.1->llama_index-embeddings-huggingface) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.8.2->llama-index-core<0.11.0,>=0.10.1->llama_index-embeddings-huggingface) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.8.2->llama-index-core<0.11.0,>=0.10.1->llama_index-embeddings-huggingface) (2024.5.15)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama_index-embeddings-huggingface) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama_index-embeddings-huggingface) (1.7.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama_index-embeddings-huggingface) (0.5.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama_index-embeddings-huggingface) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama_index-embeddings-huggingface) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama_index-embeddings-huggingface) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama_index-embeddings-huggingface) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama_index-embeddings-huggingface) (3.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama_index-embeddings-huggingface) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama_index-embeddings-huggingface) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama_index-embeddings-huggingface) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama_index-embeddings-huggingface) (3.0.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama_index-embeddings-huggingface) (1.13.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama_index-embeddings-huggingface) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers>=2.6.1->llama_index-embeddings-huggingface)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers>=2.6.1->llama_index-embeddings-huggingface)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers>=2.6.1->llama_index-embeddings-huggingface)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.11.0->sentence-transformers>=2.6.1->llama_index-embeddings-huggingface)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.11.0->sentence-transformers>=2.6.1->llama_index-embeddings-huggingface)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.11.0->sentence-transformers>=2.6.1->llama_index-embeddings-huggingface)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.11.0->sentence-transformers>=2.6.1->llama_index-embeddings-huggingface)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.11.0->sentence-transformers>=2.6.1->llama_index-embeddings-huggingface)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.11.0->sentence-transformers>=2.6.1->llama_index-embeddings-huggingface)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.11.0->sentence-transformers>=2.6.1->llama_index-embeddings-huggingface)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers>=2.6.1->llama_index-embeddings-huggingface)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama_index-embeddings-huggingface) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers>=2.6.1->llama_index-embeddings-huggingface)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers>=2.6.1->llama_index-embeddings-huggingface) (0.4.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers>=2.6.1->llama_index-embeddings-huggingface) (0.19.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama_index-embeddings-huggingface) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama_index-embeddings-huggingface) (3.21.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama_index-embeddings-huggingface) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama_index-embeddings-huggingface) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama_index-embeddings-huggingface) (2024.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers>=2.6.1->llama_index-embeddings-huggingface) (3.5.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama_index-embeddings-huggingface) (1.2.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama_index-embeddings-huggingface) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama_index-embeddings-huggingface) (2.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.1->llama_index-embeddings-huggingface) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.1->llama_index-embeddings-huggingface) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers>=2.6.1->llama_index-embeddings-huggingface) (1.3.0)\n",
            "Downloading llama_index_embeddings_huggingface-0.2.3-py3-none-any.whl (8.6 kB)\n",
            "Downloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading minijinja-2.0.1-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (853 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m853.2/853.2 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, minijinja, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, sentence-transformers, llama_index-embeddings-huggingface\n",
            "Successfully installed llama_index-embeddings-huggingface-0.2.3 minijinja-2.0.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105 sentence-transformers-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import logging\n",
        "import sys\n",
        "from llama_index.llms.openai_like import OpenAILike\n",
        "from llama_index.core import Settings, ServiceContext\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "\n",
        "# 配置日志\n",
        "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
        "\n",
        "# 定义DeepSpeed model\n",
        "llm = OpenAILike(model=\"deepseek-chat\",\n",
        "                 api_base=\"https://api.deepseek.com/v1\",\n",
        "                 api_key=os.environ[\"DEEPSEEK_API_KEY\"],\n",
        "                 temperature=0.6,\n",
        "                 is_chat_model=True)\n",
        "\n",
        "# 配置环境\n",
        "Settings.llm = llm\n",
        "\n",
        "# 设置嵌入模型\n",
        "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-zh-v1.5\")\n",
        "Settings.embed_model = embed_model\n",
        "Settings.chunk_size = 256\n",
        "service_context = ServiceContext.from_defaults(\n",
        "    llm=llm, embed_model=embed_model\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjVMPP_-1l5X",
        "outputId": "9869c152-561c-4429-f564-0aa8fddee2a2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-f86546c39a13>:25: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
            "  service_context = ServiceContext.from_defaults(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhHsmlC5vTs-"
      },
      "source": [
        "## Designing the Workflow\n",
        "\n",
        "RAG + Reranking consists of some clearly defined steps\n",
        "1. Indexing data, creating an index\n",
        "2. Using that index + a query to retrieve relevant text chunks\n",
        "3. Rerank the text retrieved text chunks using the original query\n",
        "4. Synthesizing a final response\n",
        "\n",
        "With this in mind, we can create events and workflow steps to follow this process!\n",
        "\n",
        "### The Workflow Events\n",
        "\n",
        "To handle these steps, we need to define a few events:\n",
        "1. An event to pass retrieved nodes to the reranker\n",
        "2. An event to pass reranked nodes to the synthesizer\n",
        "\n",
        "The other steps will use the built-in `StartEvent` and `StopEvent` events."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "8--nAEiSvTs-"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.workflow import Event\n",
        "from llama_index.core.schema import NodeWithScore\n",
        "\n",
        "\n",
        "class RetrieverEvent(Event):\n",
        "    \"\"\"Result of running retrieval\"\"\"\n",
        "\n",
        "    nodes: list[NodeWithScore]\n",
        "\n",
        "\n",
        "class RerankEvent(Event):\n",
        "    \"\"\"Result of running reranking on retrieved nodes\"\"\"\n",
        "\n",
        "    nodes: list[NodeWithScore]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2p4VGQzUvTs_"
      },
      "source": [
        "### The Workflow Itself\n",
        "\n",
        "With our events defined, we can construct our workflow and steps.\n",
        "\n",
        "Note that the workflow automatically validates itself using type annotations, so the type annotations on our steps are very helpful!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "mkfWUuvKvTs_"
      },
      "outputs": [],
      "source": [
        "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex\n",
        "from llama_index.core.response_synthesizers import CompactAndRefine\n",
        "from llama_index.core.postprocessor.llm_rerank import LLMRerank\n",
        "from llama_index.core.workflow import (\n",
        "    Context,\n",
        "    Workflow,\n",
        "    StartEvent,\n",
        "    StopEvent,\n",
        "    step,\n",
        ")\n",
        "\n",
        "\n",
        "class RAGWorkflow(Workflow):\n",
        "    @step(pass_context=True)\n",
        "    async def ingest(self, ctx: Context, ev: StartEvent) -> StopEvent | None:\n",
        "        \"\"\"Entry point to ingest a document, triggered by a StartEvent with `dirname`.\"\"\"\n",
        "        dirname = ev.get(\"dirname\")\n",
        "        if not dirname:\n",
        "            return None\n",
        "\n",
        "        documents = SimpleDirectoryReader(dirname).load_data()\n",
        "        ctx.data[\"index\"] = VectorStoreIndex.from_documents(\n",
        "            documents=documents,\n",
        "            embed_model=Settings.embed_model,\n",
        "            service_context=service_context\n",
        "        )\n",
        "        return StopEvent(result=f\"Indexed {len(documents)} documents.\")\n",
        "\n",
        "    @step(pass_context=True)\n",
        "    async def retrieve(\n",
        "        self, ctx: Context, ev: StartEvent\n",
        "    ) -> RetrieverEvent | None:\n",
        "        \"Entry point for RAG, triggered by a StartEvent with `query`.\"\n",
        "        query = ev.get(\"query\")\n",
        "        if not query:\n",
        "            return None\n",
        "\n",
        "        print(f\"Query the database with: {query}\")\n",
        "\n",
        "        # store the query in the global context\n",
        "        ctx.data[\"query\"] = query\n",
        "\n",
        "        # get the index from the global context\n",
        "        index = ctx.data.get(\"index\")\n",
        "        if index is None:\n",
        "            print(\"Index is empty, load some documents before querying!\")\n",
        "            return None\n",
        "\n",
        "        retriever = index.as_retriever(similarity_top_k=2)\n",
        "        nodes = retriever.retrieve(query)\n",
        "        print(f\"Retrieved {len(nodes)} nodes.\")\n",
        "        return RetrieverEvent(nodes=nodes)\n",
        "\n",
        "    @step(pass_context=True)\n",
        "    async def rerank(self, ctx: Context, ev: RetrieverEvent) -> RerankEvent:\n",
        "        # Rerank the nodes\n",
        "        ranker = LLMRerank(\n",
        "            choice_batch_size=5, top_n=3, llm=Settings.llm,\n",
        "        )\n",
        "        print(ctx.data.get(\"query\"), flush=True)\n",
        "        new_nodes = ranker.postprocess_nodes(\n",
        "            ev.nodes, query_str=ctx.data.get(\"query\")\n",
        "        )\n",
        "        print(f\"Reranked nodes to {len(new_nodes)}\")\n",
        "        return RerankEvent(nodes=new_nodes)\n",
        "\n",
        "    @step(pass_context=True)\n",
        "    async def synthesize(self, ctx: Context, ev: RerankEvent) -> StopEvent:\n",
        "        \"\"\"Return a streaming response using reranked nodes.\"\"\"\n",
        "        llm = Settings.llm\n",
        "        summarizer = CompactAndRefine(llm=llm, streaming=True, verbose=True)\n",
        "        query = ctx.data.get(\"query\")\n",
        "\n",
        "        response = await summarizer.asynthesize(query, nodes=ev.nodes)\n",
        "        return StopEvent(result=response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1T3JUaeNvTtA"
      },
      "source": [
        "And thats it! Let's explore the workflow we wrote a bit.\n",
        "\n",
        "- We have two entry points (the steps that accept `StartEvent`)\n",
        "- The steps themselves decide when they can run\n",
        "- The workflow context is used to store the user query\n",
        "- The nodes are passed around, and finally a streaming response is returned"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xpt4V6avTtB"
      },
      "source": [
        "### Run the Workflow!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![rag-workflow.webp](data:image/webp;base64,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)"
      ],
      "metadata": {
        "id": "Hkfai7YnWNa-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "lDrP7FYNvTtB"
      },
      "outputs": [],
      "source": [
        "w = RAGWorkflow()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ingest the documents\n",
        "await w.run(dirname=\"data\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xqtRRE0j4LAJ",
        "outputId": "cb673491-e2b6-414a-94f7-dad8bcc83462"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Indexed 77 documents.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "kqcEIl2SvTtC",
        "outputId": "034f1b50-217e-4f92-bf1c-6b73d6d45169",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query the database with: How was Llama2 trained?\n",
            "Retrieved 2 nodes.\n",
            "How was Llama2 trained?\n",
            "Reranked nodes to 2\n",
            "Llama 2 was trained using a new mix of publicly available online data. The models were trained with a global batch size of 4 million tokens. The training hardware included Meta’s Research Super Cluster (RSC) and internal production clusters, both utilizing NVIDIA A100s. The training process involved comparing different types of interconnects, such as NVIDIA Quantum InfiniBand and RoCE (RDMA over converged Ethernet), to determine their suitability for large-scale training."
          ]
        }
      ],
      "source": [
        "# Run a query\n",
        "result = await w.run(query=\"How was Llama2 trained?\")\n",
        "async for chunk in result.async_response_gen():\n",
        "    print(chunk, end=\"\", flush=True)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "llama-index-cDlKpkFt-py3.11",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}